{\rtf1\ansi\ansicpg1252\cocoartf2580
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red25\green25\blue25;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c12941\c12941\c12941;\cssrgb\c100000\c100000\c100000;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
(\{'acc': 0.6089238845144357,\
  'confusion_abs': [[276, 5, 15, 5, 13, 88],\
   [64, 16, 5, 14, 19, 37],\
   [6, 1, 65, 0, 1, 21],\
   [17, 0, 0, 194, 7, 38],\
   [25, 7, 15, 9, 145, 117],\
   [38, 1, 11, 32, 69, 430]],\
  'labels': [0, 1, 2, 3, 4, 5],\
  'macro-f1': 0.5502361463156171,\
  'macro-precision': 0.6064237755667395,\
  'macro-recall': 0.5496339000548282,\
  'micro-f1': 0.6089238845144357,\
  'micro-precision': 0.6089238845144357,\
  'micro-recall': 0.6089238845144357,\
  'per-label-f1': [0.6579261025029797,\
   0.16243654822335027,\
   0.625,\
   0.7475915221579962,\
   0.5061082024432809,\
   0.6413124533929904],\
  'per-label-precision': [0.6330275229357798,\
   0.5333333333333333,\
   0.5701754385964912,\
   0.7376425855513308,\
   0.5708661417322834,\
   0.5702917771883289],\
  'per-label-recall': [0.684863523573201,\
   0.09580838323353294,\
   0.6914893617021277,\
   0.7578125,\
   0.45454545454545453,\
   0.7325383304940375],\
  'weighted-f1': 0.5882910533853797,\
  'weighted-precision': 0.6053638134918031,\
  'weighted-recall': 0.6089238845144357\},\
 [[68.66, 1.24, 3.73, 1.24, 3.23, 21.89],\
  [41.29, 10.32, 3.23, 9.03, 12.26, 23.87],\
  [6.38, 1.06, 69.15, 0.0, 1.06, 22.34],\
  [6.64, 0.0, 0.0, 75.78, 2.73, 14.84],\
  [7.86, 2.2, 4.72, 2.83, 45.6, 36.79],\
  [6.54, 0.17, 1.89, 5.51, 11.88, 74.01]],\
 '              precision    recall  f1-score   support\\n\\n           0     0.6330    0.6849    0.6579       403\\n           1     0.5333    0.0958    0.1624       167\\n           2     0.5702    0.6915    0.6250        94\\n           3     0.7376    0.7578    0.7476       256\\n           4     0.5709    0.4545    0.5061       319\\n           5     0.5703    0.7325    0.6413       587\\n           6     0.6296    0.4304    0.5113        79\\n\\n    accuracy                         0.6089      1905\\n   macro avg     0.6064    0.5496    0.5502      1905\\nweighted avg     0.6054    0.6089    0.5883      1905\\n')\
\
\
======== Epoch 1 / 4 ========\
Training...\
  Batch    40  of    587.    Elapsed: 0:01:26.\
  Batch    80  of    587.    Elapsed: 0:02:52.\
  Batch   120  of    587.    Elapsed: 0:04:17.\
  Batch   160  of    587.    Elapsed: 0:05:43.\
  Batch   200  of    587.    Elapsed: 0:07:08.\
  Batch   240  of    587.    Elapsed: 0:08:34.\
  Batch   280  of    587.    Elapsed: 0:09:59.\
  Batch   320  of    587.    Elapsed: 0:11:25.\
  Batch   360  of    587.    Elapsed: 0:12:50.\
  Batch   400  of    587.    Elapsed: 0:14:16.\
  Batch   440  of    587.    Elapsed: 0:15:41.\
  Batch   480  of    587.    Elapsed: 0:17:07.\
  Batch   520  of    587.    Elapsed: 0:18:33.\
  Batch   560  of    587.    Elapsed: 0:19:58.\
\
  Average training loss: 21.30\
  Training epcoh took: 0:20:55\
\
======== Epoch 2 / 4 ========\
Training...\
  Batch    40  of    587.    Elapsed: 0:01:26.\
  Batch    80  of    587.    Elapsed: 0:02:51.\
  Batch   120  of    587.    Elapsed: 0:04:17.\
  Batch   160  of    587.    Elapsed: 0:05:42.\
  Batch   200  of    587.    Elapsed: 0:07:08.\
  Batch   240  of    587.    Elapsed: 0:08:33.\
  Batch   280  of    587.    Elapsed: 0:09:59.\
  Batch   320  of    587.    Elapsed: 0:11:24.\
  Batch   360  of    587.    Elapsed: 0:12:48.\
  Batch   400  of    587.    Elapsed: 0:14:13.\
  Batch   440  of    587.    Elapsed: 0:15:38.\
  Batch   480  of    587.    Elapsed: 0:17:03.\
  Batch   520  of    587.    Elapsed: 0:18:27.\
  Batch   560  of    587.    Elapsed: 0:19:52.\
\
  Average training loss: 16.71\
  Training epcoh took: 0:20:48\
\
======== Epoch 3 / 4 ========\
Training...\
  Batch    40  of    587.    Elapsed: 0:01:25.\
  Batch    80  of    587.    Elapsed: 0:02:49.\
  Batch   120  of    587.    Elapsed: 0:04:14.\
  Batch   160  of    587.    Elapsed: 0:05:39.\
  Batch   200  of    587.    Elapsed: 0:07:04.\
  Batch   240  of    587.    Elapsed: 0:08:28.\
  Batch   280  of    587.    Elapsed: 0:09:53.\
  Batch   320  of    587.    Elapsed: 0:11:18.\
  Batch   360  of    587.    Elapsed: 0:12:43.\
  Batch   400  of    587.    Elapsed: 0:14:08.\
  Batch   440  of    587.    Elapsed: 0:15:33.\
  Batch   480  of    587.    Elapsed: 0:16:58.\
  Batch   520  of    587.    Elapsed: 0:18:22.\
  Batch   560  of    587.    Elapsed: 0:19:47.\
\
  Average training loss: 13.84\
  Training epcoh took: 0:20:44\
\
======== Epoch 4 / 4 ========\
Training...\
  Batch    40  of    587.    Elapsed: 0:01:25.\
  Batch    80  of    587.    Elapsed: 0:02:50.\
  Batch   120  of    587.    Elapsed: 0:04:14.\
  Batch   160  of    587.    Elapsed: 0:05:39.\
  Batch   200  of    587.    Elapsed: 0:07:04.\
  Batch   240  of    587.    Elapsed: 0:08:29.\
  Batch   280  of    587.    Elapsed: 0:09:54.\
  Batch   320  of    587.    Elapsed: 0:11:19.\
  Batch   360  of    587.    Elapsed: 0:12:44.\
  Batch   400  of    587.    Elapsed: 0:14:09.\
  Batch   440  of    587.    Elapsed: 0:15:34.\
  Batch   480  of    587.    Elapsed: 0:16:58.\
  Batch   520  of    587.    Elapsed: 0:18:24.\
  Batch   560  of    587.    Elapsed: 0:19:49.\
\
  Average training loss: 11.52\
  Training epcoh took: 0:20:46\
\
Training complete!\
Total training took 1:23:13 (h:mm:ss)}
{\rtf1\ansi\ansicpg1252\cocoartf2580
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red25\green25\blue25;\red255\green255\blue255;}
{\*\expandedcolortbl;;\cssrgb\c12941\c12941\c12941;\cssrgb\c100000\c100000\c100000;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
(\{'acc': 0.5123359580052493,\
  'confusion_abs': [[215, 0, 8, 10, 28, 141],\
   [58, 1, 6, 9, 24, 64],\
   [4, 0, 64, 0, 1, 25],\
   [15, 0, 0, 173, 22, 46],\
   [30, 0, 13, 21, 102, 153],\
   [56, 0, 14, 43, 78, 394]],\
  'labels': [0, 1, 2, 3, 4, 5],\
  'macro-f1': 0.4622299058915228,\
  'macro-precision': 0.6349401082487407,\
  'macro-recall': 0.46126428647440576,\
  'micro-f1': 0.5123359580052493,\
  'micro-precision': 0.5123359580052493,\
  'micro-recall': 0.5123359580052493,\
  'per-label-f1': [0.5470737913486006,\
   0.011904761904761906,\
   0.64,\
   0.6628352490421455,\
   0.3547826086956522,\
   0.5453287197231834],\
  'per-label-precision': [0.5613577023498695,\
   1.0,\
   0.6037735849056604,\
   0.650375939849624,\
   0.3984375,\
   0.4592074592074592],\
  'per-label-recall': [0.533498759305211,\
   0.005988023952095809,\
   0.6808510638297872,\
   0.67578125,\
   0.31974921630094044,\
   0.6712095400340715],\
  'weighted-f1': 0.48451932818339694,\
  'weighted-precision': 0.563820110145548,\
  'weighted-recall': 0.5123359580052493\},\
 [[53.48, 0.0, 1.99, 2.49, 6.97, 35.07],\
  [35.8, 0.62, 3.7, 5.56, 14.81, 39.51],\
  [4.26, 0.0, 68.09, 0.0, 1.06, 26.6],\
  [5.86, 0.0, 0.0, 67.58, 8.59, 17.97],\
  [9.4, 0.0, 4.08, 6.58, 31.97, 47.96],\
  [9.57, 0.0, 2.39, 7.35, 13.33, 67.35]],\
 '              precision    recall  f1-score   support\\n\\n           0     0.5614    0.5335    0.5471       403\\n           1     1.0000    0.0060    0.0119       167\\n           2     0.6038    0.6809    0.6400        94\\n           3     0.6504    0.6758    0.6628       256\\n           4     0.3984    0.3197    0.3548       319\\n           5     0.4592    0.6712    0.5453       587\\n           6     0.7714    0.3418    0.4737        79\\n\\n    accuracy                         0.5123      1905\\n   macro avg     0.6349    0.4613    0.4622      1905\\nweighted avg     0.5638    0.5123    0.4845      1905\\n')\
\
\
======== Epoch 1 / 5 ========\
Training...\
  Batch    40  of    587.    Elapsed: 0:00:56.\
  Batch    80  of    587.    Elapsed: 0:01:53.\
  Batch   120  of    587.    Elapsed: 0:02:49.\
  Batch   160  of    587.    Elapsed: 0:03:45.\
  Batch   200  of    587.    Elapsed: 0:04:41.\
  Batch   240  of    587.    Elapsed: 0:05:37.\
  Batch   280  of    587.    Elapsed: 0:06:33.\
  Batch   320  of    587.    Elapsed: 0:07:29.\
  Batch   360  of    587.    Elapsed: 0:08:25.\
  Batch   400  of    587.    Elapsed: 0:09:21.\
  Batch   440  of    587.    Elapsed: 0:10:17.\
  Batch   480  of    587.    Elapsed: 0:11:13.\
  Batch   520  of    587.    Elapsed: 0:12:09.\
  Batch   560  of    587.    Elapsed: 0:13:05.\
\
  Average training loss: 1.53\
  Training epcoh took: 0:13:42\
\
======== Epoch 2 / 5 ========\
Training...\
  Batch    40  of    587.    Elapsed: 0:00:56.\
  Batch    80  of    587.    Elapsed: 0:01:52.\
  Batch   120  of    587.    Elapsed: 0:02:48.\
  Batch   160  of    587.    Elapsed: 0:03:44.\
  Batch   200  of    587.    Elapsed: 0:04:40.\
  Batch   240  of    587.    Elapsed: 0:05:36.\
  Batch   280  of    587.    Elapsed: 0:06:32.\
  Batch   320  of    587.    Elapsed: 0:07:28.\
  Batch   360  of    587.    Elapsed: 0:08:23.\
  Batch   400  of    587.    Elapsed: 0:09:19.\
  Batch   440  of    587.    Elapsed: 0:10:15.\
  Batch   480  of    587.    Elapsed: 0:11:11.\
  Batch   520  of    587.    Elapsed: 0:12:07.\
  Batch   560  of    587.    Elapsed: 0:13:03.\
\
  Average training loss: 1.29\
  Training epcoh took: 0:13:40\
\
======== Epoch 3 / 5 ========\
Training...\
  Batch    40  of    587.    Elapsed: 0:00:56.\
  Batch    80  of    587.    Elapsed: 0:01:52.\
  Batch   120  of    587.    Elapsed: 0:02:48.\
  Batch   160  of    587.    Elapsed: 0:03:44.\
  Batch   200  of    587.    Elapsed: 0:04:40.\
  Batch   240  of    587.    Elapsed: 0:05:36.\
  Batch   280  of    587.    Elapsed: 0:06:32.\
  Batch   320  of    587.    Elapsed: 0:07:28.\
  Batch   360  of    587.    Elapsed: 0:08:24.\
  Batch   400  of    587.    Elapsed: 0:09:20.\
  Batch   440  of    587.    Elapsed: 0:10:16.\
  Batch   480  of    587.    Elapsed: 0:11:12.\
  Batch   520  of    587.    Elapsed: 0:12:08.\
  Batch   560  of    587.    Elapsed: 0:13:04.\
\
  Average training loss: 1.10\
  Training epcoh took: 0:13:40\
\
======== Epoch 4 / 5 ========\
Training...\
  Batch    40  of    587.    Elapsed: 0:00:56.\
  Batch    80  of    587.    Elapsed: 0:01:51.\
  Batch   120  of    587.    Elapsed: 0:02:47.\
  Batch   160  of    587.    Elapsed: 0:03:42.\
  Batch   200  of    587.    Elapsed: 0:04:38.\
  Batch   240  of    587.    Elapsed: 0:05:33.\
  Batch   280  of    587.    Elapsed: 0:06:29.\
  Batch   320  of    587.    Elapsed: 0:07:24.\
  Batch   360  of    587.    Elapsed: 0:08:19.\
  Batch   400  of    587.    Elapsed: 0:09:15.\
  Batch   440  of    587.    Elapsed: 0:10:11.\
  Batch   480  of    587.    Elapsed: 0:11:07.\
  Batch   520  of    587.    Elapsed: 0:12:02.\
  Batch   560  of    587.    Elapsed: 0:12:58.\
\
  Average training loss: 0.94\
  Training epcoh took: 0:13:35\
\
======== Epoch 5 / 5 ========\
Training...\
  Batch    40  of    587.    Elapsed: 0:00:56.\
  Batch    80  of    587.    Elapsed: 0:01:52.\
  Batch   120  of    587.    Elapsed: 0:02:48.\
  Batch   160  of    587.    Elapsed: 0:03:45.\
  Batch   200  of    587.    Elapsed: 0:04:41.\
  Batch   240  of    587.    Elapsed: 0:05:37.\
  Batch   280  of    587.    Elapsed: 0:06:33.\
  Batch   320  of    587.    Elapsed: 0:07:29.\
  Batch   360  of    587.    Elapsed: 0:08:25.\
  Batch   400  of    587.    Elapsed: 0:09:21.\
  Batch   440  of    587.    Elapsed: 0:10:16.\
  Batch   480  of    587.    Elapsed: 0:11:12.\
  Batch   520  of    587.    Elapsed: 0:12:07.\
  Batch   560  of    587.    Elapsed: 0:13:03.\
\
  Average training loss: 0.84\
  Training epcoh took: 0:13:40\
\
Training complete!\
Total training took 1:08:16 (h:mm:ss)}